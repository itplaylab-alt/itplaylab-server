// liteClient.js â€” ItplayLab LITE ì—”ì§„ ì „ìš© í´ë¼ì´ì–¸íŠ¸
// ì—­í• : LITE_SYSTEM_PROMPT + gpt-4o-mini ì‚¬ìš©í•´ì„œ ë¹ ë¥¸ JSON ì‘ë‹µ ìƒì„±

import OpenAI from "openai";

const {
  OPENAI_API_KEY,
  LITE_SYSTEM_PROMPT,
  LITE_MODEL = "gpt-4o-mini",
} = process.env;

const oa = new OpenAI({ apiKey: OPENAI_API_KEY });

/**
 * LITE ì „ìš© í˜¸ì¶œì
 * @param {string} task  - "brief" | "script" ë“± ì‘ì—…ëª…
 * @param {any} payload  - ì‹¤ì œ ì…ë ¥ ë°ì´í„° (idea, brief ë“±)
 * @param {object} meta  - pattern_hint ë“± ë¶€ê°€ ë©”íƒ€
 */
export async function callLiteGPT(task, payload = {}, meta = {}) {
  const started = Date.now();

  if (!OPENAI_API_KEY) {
    return {
      ok: false,
      output: null,
      error: {
        code: "NO_API_KEY",
        message: "OPENAI_API_KEY missing",
      },
      debug: {
        engine: LITE_MODEL,
        latency_ms: 0,
      },
    };
  }

  const systemPrompt =
    LITE_SYSTEM_PROMPT ||
    "ë„ˆëŠ” ItplayLab LITE ì—”ì§„ì´ë‹¤. í•­ìƒ JSON í•˜ë‚˜ë§Œ ë°˜í™˜í•˜ë¼.";

  // user ìª½ì— ì „ë‹¬í•  í˜ì´ë¡œë“œ(ë¬¸ìì—´)
  const userInput = JSON.stringify({
    task,
    input: payload,
    meta,
  });

  try {
    // ğŸ”‘ ì—¬ê¸°ì„œ Responses API ê·œê²©ì„ ë§ì¶¤
    const resp = await oa.responses.create({
      model: LITE_MODEL,
      input: [
        {
          role: "system",
          content: [
            {
              // *** ì¤‘ìš”: ResponsesëŠ” type: "input_text" ì—¬ì•¼ í•¨ ***
              type: "input_text",
              text: systemPrompt,
            },
          ],
        },
        {
          role: "user",
          content: [
            {
              type: "input_text",
              text: userInput,
            },
          ],
        },
      ],
      response_format: { type: "json_object" },
      temperature: 0.2,
    });

    // í…ìŠ¤íŠ¸ êº¼ë‚´ê¸° (Responses í‘œì¤€)
    const txt =
      resp?.output?.[0]?.content?.[0]?.text || resp?.output_text || "";

    let parsed;
    try {
      parsed = txt ? JSON.parse(txt) : null;
    } catch (e) {
      return {
        ok: false,
        output: null,
        error: {
          code: "JSON_PARSE_ERROR",
          message: e.message,
          raw: txt,
        },
        debug: {
          engine: LITE_MODEL,
          latency_ms: Date.now() - started,
        },
      };
    }

    // LITE_SYSTEM_PROMPTì—ì„œ ì •ì˜í•œ ìµœìƒìœ„ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ë°›ëŠ” ê±¸ ê°€ì •:
    // { task, ok, output, meta, debug }
    const outerOk =
      typeof parsed?.ok === "boolean" ? parsed.ok : true;

    return {
      ok: outerOk,
      output: parsed?.output ?? parsed,
      error: outerOk ? null : parsed?.error ?? null,
      debug: {
        engine:
          parsed?.debug?.engine ||
          resp?.model ||
          LITE_MODEL,
        latency_ms:
          parsed?.debug?.latency_ms ||
          Date.now() - started,
      },
    };
  } catch (e) {
    return {
      ok: false,
      output: null,
      error: {
        code: "OPENAI_ERROR",
        message: e?.message || "unknown_openai_error",
        details: e?.response?.data,
      },
      debug: {
        engine: LITE_MODEL,
        latency_ms: Date.now() - started,
      },
    };
  }
}
